---
title: "Denoising Autoencoders"
date: "2025-11-06"
description: "Convolutional autoencoder system for removing Gaussian and non-Gaussian noise from images using encoder-decoder architecture with skip connections."
tech: ["PyTorch", "NumPy", "TensorBoard"]
---

<div className="flex flex-wrap items-center gap-3 not-prose mb-6">
  <a href="https://github.com/krishmula/denoising-autoencoders" target="_blank" className="inline-flex items-center gap-2 px-3 py-1.5 text-sm rounded-md bg-highlight border border-muted text-foreground hover:border-foreground/30 transition-colors no-underline">
    <svg className="w-4 h-4" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"/></svg>
    GitHub
  </a>
  <span className="inline-flex items-center gap-2 px-3 py-1.5 text-sm rounded-md border border-dashed border-muted/50 text-muted-foreground/50 cursor-not-allowed">
    <svg className="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path strokeLinecap="round" strokeLinejoin="round" strokeWidth="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z"/><path strokeLinecap="round" strokeLinejoin="round" strokeWidth="2" d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z"/></svg>
    Live Demo Coming Soon
  </span>
</div>

Denoising autoencoder that restores corrupted images by learning compressed latent representations through a bottleneck architecture. The system trains on synthetically noised images and learns to reconstruct clean versions, handling both Gaussian noise and more complex noise patterns. Developed as part of SJSU AI/ML Club's Fall 2025 research initiative.

## Encoder-Decoder Architecture

The model implements a symmetric convolutional architecture with a compressed latent space. The encoder progressively reduces spatial dimensions through strided convolutions while expanding feature channels, creating information-rich representations at the bottleneck. The decoder mirrors this structure with transposed convolutions, reconstructing full-resolution images while preserving fine-grained details through skip connections between corresponding encoder-decoder layers.

## Technical Features

- **Multi-scale Feature Extraction** — Convolutional encoder with downsampling stages capturing hierarchical image features from edges to textures

- **Bottleneck Compression** — Reduces input to a compact latent representation, forcing the network to learn efficient noise-invariant encodings

- **Skip Connections** — Element-wise concatenation between encoder and decoder feature maps at matching resolutions, preserving spatial information lost during compression

- **Adaptive Noise Injection** — Training pipeline generates synthetic noisy images with configurable Gaussian and salt-and-pepper noise parameters

- **Combined Loss Function** — MSE + perceptual loss for pixel-wise reconstruction while maintaining visual quality

- **Batch Normalization** — Layer normalization after each convolution block for training stability and faster convergence

## Architecture

The training pipeline loads CIFAR-10 images, applies random noise augmentation, and feeds corrupted-clean pairs to the model. The encoder uses ReLU activations with max pooling for downsampling, while the decoder employs transposed convolutions with nearest-neighbor upsampling. The system tracks PSNR/SSIM/MSE metrics during training and validates on a held-out test set with varying noise intensities.

## Tech Stack

<div className="flex flex-wrap gap-2 not-prose">
  <span className="px-3 py-1 text-sm rounded-full bg-highlight text-foreground border border-muted">PyTorch</span>
  <span className="px-3 py-1 text-sm rounded-full bg-highlight text-foreground border border-muted">NumPy</span>
  <span className="px-3 py-1 text-sm rounded-full bg-highlight text-foreground border border-muted">Matplotlib</span>
  <span className="px-3 py-1 text-sm rounded-full bg-highlight text-foreground border border-muted">TensorBoard</span>
  <span className="px-3 py-1 text-sm rounded-full bg-highlight text-foreground border border-muted">PIL</span>
  <span className="px-3 py-1 text-sm rounded-full bg-highlight text-foreground border border-muted">CIFAR-10</span>
</div>


{/* ## What I Built

Led the Team A implementation, designing the baseline convolutional autoencoder architecture. Implemented the custom noise injection module that generates training pairs and built the training loop with gradient clipping and learning rate scheduling. Conducted experiments comparing different bottleneck sizes and loss function combinations, establishing baseline metrics for the team to iterate on. */}